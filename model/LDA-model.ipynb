{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T14:21:21.018556Z",
     "start_time": "2025-06-29T14:21:16.876896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "18a5991ea75b9707",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\markl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\markl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\markl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T23:25:14.980606Z",
     "start_time": "2025-06-29T23:25:14.954682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize stopwords and lemmatizer outside the function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    custom_stopwords = set(line.strip().lower() for line in f if line.strip())\n",
    "\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "# Special handling for forum text\n",
    "forum_patterns = [\n",
    "    (r'smilies?\\w+\\s?\\w*\\s?\\d+', ''),  # Remove smiley codes\n",
    "    (r'//.*', ''),                      # Remove code-like comments\n",
    "    (r'\\.{2,}', ' '),                   # Replace multiple dots\n",
    "    (r'[^\\w\\s]', ' ')                   # Keep only words and spaces\n",
    "]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "id": "9ccc1cd8545992e6",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T23:25:19.480938Z",
     "start_time": "2025-06-29T23:25:19.203426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the CSV file\n",
    "file_path = \"C:\\\\Users\\\\markl\\\\Downloads\\\\archive\\\\climate_posts_clean.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Get random sample of 250 entries\n",
    "    sample_size = 500\n",
    "    if len(df) > sample_size:\n",
    "        df = df.sample(n=sample_size, random_state=42)\n",
    "    documents = df['text'].astype(str).tolist()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "    exit()"
   ],
   "id": "81a5fa81ac100a18",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T23:25:27.440206Z",
     "start_time": "2025-06-29T23:25:21.100470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text, bigram_model=None):\n",
    "    \"\"\"\n",
    "    Enhanced text preprocessing for LDA with bigram support:\n",
    "    1. Comprehensive cleaning (URLs, emails, etc.)\n",
    "    2. Advanced contraction handling\n",
    "    3. Multi-stage filtering (stopwords, length, alphanumeric)\n",
    "    4. Optional bigram processing\n",
    "    \"\"\"\n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')  # Remove line breaks\n",
    "\n",
    "    # Advanced cleaning\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # URLs\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)             # Emails\n",
    "    text = re.sub(r'[^\\w\\s]|\\d', ' ', text)            # Remove punctuation/numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()           # Trim whitespace\n",
    "    text = re.sub(r'\\b(may|would|could|might)\\b', '', text)  # Remove modals\n",
    "    text = ' '.join([word for word in text.split() if word not in custom_stopwords])\n",
    "    text = re.sub(r'\\b\\w{1,3}\\b', '', text)  # Remove very short words\n",
    "    text = re.sub(r'\\b(?:look|interesting|using|well|find)\\b', '', text)\n",
    "    text = re.sub(r'\\b\\w{5,20}\\b', lambda x: x.group() if x.group() in {\n",
    "        'climate', 'change', 'global', 'warming',\n",
    "        'science', 'data', 'research'\n",
    "    } else '', text)\n",
    "\n",
    "    # Enhanced contraction handling\n",
    "    contractions = {\n",
    "        \"don't\": \"do not\", \"can't\": \"cannot\", \"won't\": \"will not\",\n",
    "        \"it's\": \"it is\", \"i'm\": \"i am\", \"you're\": \"you are\",\n",
    "        \"they're\": \"they are\", \"that's\": \"that is\", \"there's\": \"there is\",\n",
    "        \"he's\": \"he is\", \"she's\": \"she is\", \"what's\": \"what is\"\n",
    "    }\n",
    "    for cont, expanded in contractions.items():\n",
    "        text = text.replace(cont, expanded)\n",
    "\n",
    "    # Tokenization and lemmatization\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [\n",
    "            lemmatizer.lemmatize(token)\n",
    "            for token in tokens\n",
    "            if (token not in stop_words and\n",
    "                3 <= len(token) <= 25 and\n",
    "                token.isalpha())\n",
    "        ]\n",
    "\n",
    "        # Apply bigram model if provided\n",
    "        if bigram_model:\n",
    "            tokens = bigram_model[tokens]\n",
    "\n",
    "        return tokens\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return []\n",
    "\n",
    "# Preprocess documents\n",
    "processed_docs = [preprocess_text(text) for text in documents]\n",
    "processed_docs = [doc for doc in processed_docs if len(doc) > 0]\n",
    "\n",
    "term_merges = {\n",
    "    'climate': 'climate_science',\n",
    "    'science': 'climate_science',\n",
    "    'global': 'global_warming',\n",
    "    'warming': 'global_warming',\n",
    "    'fuel': 'fossil_fuels',\n",
    "}\n",
    "\n",
    "processed_docs = [\n",
    "    [term_merges.get(word, word) for word in doc]\n",
    "    for doc in processed_docs\n",
    "]\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# # Test multiple topic numbers\n",
    "# coherence_scores = []\n",
    "# for num_topics in range(2, 8):\n",
    "#     lda = LdaModel(\n",
    "#         corpus=bow_corpus,\n",
    "#         id2word=dictionary,\n",
    "#         num_topics=num_topics,\n",
    "#         passes=30\n",
    "#     )\n",
    "#     cm = CoherenceModel(\n",
    "#         model=lda,\n",
    "#         texts=processed_docs,\n",
    "#         dictionary=dictionary,\n",
    "#         coherence='c_v'\n",
    "#     )\n",
    "#     coherence_scores.append(cm.get_coherence())\n",
    "#\n",
    "# # Plot results\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(range(2,8), coherence_scores)\n",
    "# plt.xlabel(\"Number of Topics\")\n",
    "# plt.ylabel(\"Coherence Score\")\n",
    "# plt.show()\n",
    "\n",
    "# LDA Model with 3 topics\n",
    "lda_model = LdaModel(\n",
    "    corpus=bow_corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=3,\n",
    "    random_state=42,\n",
    "    passes=50,\n",
    "    alpha='asymmetric'\n",
    ")\n",
    "\n",
    "# Evaluate LDA\n",
    "coherence_model = CoherenceModel(\n",
    "    model=lda_model,\n",
    "    texts=processed_docs,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "# Calculate perplexity\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)  # This returns bound, need to convert\n",
    "actual_perplexity = 2 ** (-perplexity)  # Convert to actual perplexity\n",
    "\n",
    "print(\"\\nLDA Topics:\")\n",
    "for idx, topic in lda_model.print_topics(-1, num_words=10):\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "print(f\"\\nCoherence Score: {coherence_score:.4f}\")\n",
    "print(f\"Perplexity: {actual_perplexity:.4f}\")\n",
    "\n",
    "# Interpretation notes\n",
    "print(\"\\nModel Evaluation Notes:\")\n",
    "print(\"- Higher coherence scores (closer to 1) indicate better topic quality\")\n",
    "print(\"- Lower perplexity scores indicate better model performance\")\n",
    "print(\"- Ideal model has high coherence and low perplexity\")"
   ],
   "id": "1918a23b77ff2021",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Topics:\n",
      "Topic 0: 0.458*\"climate_science\" + 0.169*\"data\" + 0.113*\"change\" + 0.049*\"heat\" + 0.041*\"nasa\" + 0.033*\"research\" + 0.031*\"land\" + 0.026*\"ipcc\" + 0.022*\"area\" + 0.021*\"temp\"\n",
      "Topic 1: 0.497*\"fossil_fuels\" + 0.192*\"one\" + 0.098*\"ipcc\" + 0.056*\"nasa\" + 0.037*\"research\" + 0.014*\"past\" + 0.012*\"climate_science\" + 0.011*\"change\" + 0.011*\"global_warming\" + 0.011*\"lie\"\n",
      "Topic 2: 0.679*\"global_warming\" + 0.115*\"climate_science\" + 0.100*\"change\" + 0.056*\"past\" + 0.026*\"research\" + 0.005*\"lie\" + 0.005*\"say\" + 0.001*\"temp\" + 0.001*\"heat\" + 0.001*\"land\"\n",
      "\n",
      "Coherence Score: 0.5353\n",
      "Perplexity: 4.5078\n",
      "\n",
      "Model Evaluation Notes:\n",
      "- Higher coherence scores (closer to 1) indicate better topic quality\n",
      "- Lower perplexity scores indicate better model performance\n",
      "- Ideal model has high coherence and low perplexity\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a7905eeef7e82be4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
